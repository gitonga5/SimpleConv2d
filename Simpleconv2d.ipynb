
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ced394b",
   "metadata": {},
   "source": [
    "##### 【Problem 1 】 Creation of 2D convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7931edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size  # (height, width)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.W = np.random.randn(kernel_size[0], kernel_size[1], in_channels, out_channels)\n",
    "        self.b = np.zeros(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        N, C, H, W = x.shape\n",
    "        FH, FW = self.kernel_size\n",
    "        out_h = (H + 2*self.padding - FH) // self.stride + 1\n",
    "        out_w = (W + 2*self.padding - FW) // self.stride + 1\n",
    "\n",
    "        self.out_h, self.out_w = out_h, out_w\n",
    "\n",
    "        if self.padding > 0:\n",
    "            x = np.pad(x, ((0,0), (0,0), (self.padding,self.padding), (self.padding,self.padding)), 'constant')\n",
    "\n",
    "        out = np.zeros((N, self.out_channels, out_h, out_w))\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * self.stride\n",
    "                w_start = j * self.stride\n",
    "                region = x[:, :, h_start:h_start+FH, w_start:w_start+FW]\n",
    "                for m in range(self.out_channels):\n",
    "                    out[:, m, i, j] = np.sum(region * self.W[:, :, :, m], axis=(1, 2, 3)) + self.b[m]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, C, H, W = self.x.shape\n",
    "        FH, FW = self.kernel_size\n",
    "\n",
    "        dx = np.zeros_like(self.x)\n",
    "        dW = np.zeros_like(self.W)\n",
    "        db = np.zeros_like(self.b)\n",
    "\n",
    "        for i in range(self.out_h):\n",
    "            for j in range(self.out_w):\n",
    "                h_start = i * self.stride\n",
    "                w_start = j * self.stride\n",
    "                region = self.x[:, :, h_start:h_start+FH, w_start:w_start+FW]\n",
    "                for m in range(self.out_channels):\n",
    "                    db[m] += np.sum(dout[:, m, i, j])\n",
    "                    for n in range(N):\n",
    "                        dW[:, :, :, m] += region[n] * dout[n, m, i, j]\n",
    "                        dx[n, :, h_start:h_start+FH, w_start:w_start+FW] += self.W[:, :, :, m] * dout[n, m, i, j]\n",
    "\n",
    "        self.dW = dW\n",
    "        self.db = db\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460c74d",
   "metadata": {},
   "source": [
    "##### Problem 2 】 Experiment of 2D convolution layer in small array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80808a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.  0.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[12. 12.]\n",
      "   [12. 12.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Input and weights\n",
    "x = np.array([[[[ 1,  2,  3,  4],\n",
    "                [ 5,  6,  7,  8],\n",
    "                [ 9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]]]])  # shape (1,1,4,4)\n",
    "\n",
    "w = np.array([[[[ 0.,  0.,  0.],\n",
    "                [ 0.,  1.,  0.],\n",
    "                [ 0., -1.,  0.]]],\n",
    "\n",
    "              [[[ 0.,  0.,  0.],\n",
    "                [ 0., -1.,  1.],\n",
    "                [ 0.,  0.,  0.]]]])  # shape (2,1,3,3) NHWC → NCHW compatible\n",
    "\n",
    "# Manually set weights to match shape\n",
    "conv = Conv2d(in_channels=1, out_channels=2, kernel_size=(3, 3))\n",
    "conv.W = w.transpose(2, 3, 1, 0)  # convert from (2,1,3,3) to (3,3,1,2)\n",
    "conv.b = np.array([0, 0])\n",
    "\n",
    "# Forward\n",
    "out = conv.forward(x)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f42ea7",
   "metadata": {},
   "source": [
    "##### 【Problem 3 】 Output size after two-dimensional convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d539325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_output_size(H_in, W_in, FH, FW, SH, SW, PH, PW):\n",
    "    H_out = (H_in + 2*PH - FH) // SH + 1\n",
    "    W_out = (W_in + 2*PW - FW) // SW + 1\n",
    "    return H_out, W_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984ade3",
   "metadata": {},
   "source": [
    "##### 【Problem 4 】 Creating a maximum pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506bdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        N, C, H, W = x.shape\n",
    "        FH, FW = self.kernel_size\n",
    "        SH, SW = self.stride\n",
    "        out_h = (H - FH) // SH + 1\n",
    "        out_w = (W - FW) // SW + 1\n",
    "\n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        self.argmax = np.zeros_like(x)\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * SH\n",
    "                w_start = j * SW\n",
    "                region = x[:, :, h_start:h_start+FH, w_start:w_start+FW]\n",
    "                out[:, :, i, j] = np.max(region, axis=(2, 3))\n",
    "\n",
    "                max_mask = (region == np.expand_dims(out[:, :, i, j], axis=(2, 3)))\n",
    "                self.argmax[:, :, h_start:h_start+FH, w_start:w_start+FW] += max_mask\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.zeros_like(self.x)\n",
    "        FH, FW = self.kernel_size\n",
    "        SH, SW = self.stride\n",
    "        N, C, out_h, out_w = dout.shape\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * SH\n",
    "                w_start = j * SW\n",
    "                max_mask = self.argmax[:, :, h_start:h_start+FH, w_start:w_start+FW]\n",
    "                dx[:, :, h_start:h_start+FH, w_start:w_start+FW] += max_mask * np.expand_dims(dout[:, :, i, j], axis=(2, 3))\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2bbb1",
   "metadata": {},
   "source": [
    "##### 【Problem 5 】 (Advance Challenge) Create average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d98aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool2D:\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        N, C, H, W = x.shape\n",
    "        FH, FW = self.kernel_size\n",
    "        SH, SW = self.stride\n",
    "        out_h = (H - FH) // SH + 1\n",
    "        out_w = (W - FW) // SW + 1\n",
    "\n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * SH\n",
    "                w_start = j * SW\n",
    "                region = x[:, :, h_start:h_start+FH, w_start:w_start+FW]\n",
    "                out[:, :, i, j] = np.mean(region, axis=(2, 3))\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FH, FW = self.kernel_size\n",
    "        SH, SW = self.stride\n",
    "        dx = np.zeros_like(self.x)\n",
    "        N, C, out_h, out_w = dout.shape\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * SH\n",
    "                w_start = j * SW\n",
    "                dx[:, :, h_start:h_start+FH, w_start:w_start+FW] += (dout[:, :, i, j][:, :, None, None] / (FH * FW))\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167e9e5",
   "metadata": {},
   "source": [
    "##### 【Problem 6 】 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b23432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, x):\n",
    "        self.orig_shape = x.shape\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.orig_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7813c0e",
   "metadata": {},
   "source": [
    "##### 【Problem 7 】 Learning and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9b8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), stride=1, padding=0)\n",
    "        self.pool1 = AveragePool2D(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=1, padding=0)\n",
    "        self.pool2 = AveragePool2D(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = FullyConnected(16 * 5 * 5, 120)\n",
    "        self.fc2 = FullyConnected(120, 84)\n",
    "        self.fc3 = FullyConnected(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1.forward(x)\n",
    "        x = self.pool1.forward(x)\n",
    "        x = self.conv2.forward(x)\n",
    "        x = self.pool2.forward(x)\n",
    "        x = self.flatten.forward(x)\n",
    "        x = self.fc1.forward(x)\n",
    "        x = self.fc2.forward(x)\n",
    "        x = self.fc3.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = self.fc3.backward(dout)\n",
    "        dout = self.fc2.backward(dout)\n",
    "        dout = self.fc1.backward(dout)\n",
    "        dout = self.flatten.backward(dout)\n",
    "        dout = self.pool2.backward(dout)\n",
    "        dout = self.conv2.backward(dout)\n",
    "        dout = self.pool1.backward(dout)\n",
    "        dout = self.conv1.backward(dout)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e97d07",
   "metadata": {},
   "source": [
    "##### 【Problem 8 】 (Advance Challenge) LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298810fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ReLU activation function\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        return dout\n",
    "\n",
    "# Softmax and Cross-Entropy Loss\n",
    "class SoftmaxWithLoss:\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(x)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        x = x - np.max(x, axis=1, keepdims=True)\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        delta = 1e-7\n",
    "        return -np.sum(t * np.log(y + delta)) / y.shape[0]\n",
    "\n",
    "# 2D Convolution Layer\n",
    "class Conv2D:\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride=1, padding=0):\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.W = np.random.randn(output_channels, input_channels, kernel_size, kernel_size) * 0.1\n",
    "        self.b = np.zeros(output_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, in_channels, height, width = x.shape\n",
    "        out_height = (height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        out_width = (width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        \n",
    "        self.output = np.zeros((batch_size, self.output_channels, out_height, out_width))\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            for c in range(self.output_channels):\n",
    "                for i in range(0, height - self.kernel_size + 1, self.stride):\n",
    "                    for j in range(0, width - self.kernel_size + 1, self.stride):\n",
    "                        self.output[b, c, i // self.stride, j // self.stride] = np.sum(\n",
    "                            x[b, :, i:i + self.kernel_size, j:j + self.kernel_size] * self.W[c, :, :, :]\n",
    "                        ) + self.b[c]\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        batch_size, out_channels, out_height, out_width = dout.shape\n",
    "        dx = np.zeros_like(self.x)\n",
    "        dW = np.zeros_like(self.W)\n",
    "        db = np.zeros_like(self.b)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            for c in range(self.output_channels):\n",
    "                for i in range(0, self.x.shape[2] - self.kernel_size + 1, self.stride):\n",
    "                    for j in range(0, self.x.shape[3] - self.kernel_size + 1, self.stride):\n",
    "                        region = self.x[b, :, i:i + self.kernel_size, j:j + self.kernel_size]\n",
    "                        dW[c] += dout[b, c, i // self.stride, j // self.stride] * region\n",
    "                        dx[b, :, i:i + self.kernel_size, j:j + self.kernel_size] += dout[b, c, i // self.stride, j // self.stride] * self.W[c]\n",
    "                db[c] += np.sum(dout[b, c])\n",
    "\n",
    "        return dx, dW, db\n",
    "\n",
    "# Max Pooling Layer\n",
    "class MaxPool2D:\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        out_height = (height - self.pool_size) // self.stride + 1\n",
    "        out_width = (width - self.pool_size) // self.stride + 1\n",
    "        \n",
    "        self.output = np.zeros((batch_size, channels, out_height, out_width))\n",
    "        self.mask = np.zeros_like(self.output)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            for c in range(channels):\n",
    "                for i in range(0, height - self.pool_size + 1, self.stride):\n",
    "                    for j in range(0, width - self.pool_size + 1, self.stride):\n",
    "                        region = x[b, c, i:i + self.pool_size, j:j + self.pool_size]\n",
    "                        self.output[b, c, i // self.stride, j // self.stride] = np.max(region)\n",
    "                        self.mask[b, c, i // self.stride, j // self.stride] = np.argmax(region)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.zeros_like(self.x)\n",
    "        for b in range(dout.shape[0]):\n",
    "            for c in range(dout.shape[1]):\n",
    "                for i in range(dout.shape[2]):\n",
    "                    for j in range(dout.shape[3]):\n",
    "                        max_index = self.mask[b, c, i, j]\n",
    "                        dx[b, c, i * self.pool_size + max_index // self.pool_size, j * self.pool_size + max_index % self.pool_size] = dout[b, c, i, j]\n",
    "        return dx\n",
    "\n",
    "# Flatten Layer\n",
    "class Flatten:\n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.input_shape)\n",
    "\n",
    "# Fully Connected Layer\n",
    "class FullyConnected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = np.random.randn(input_size, output_size) * 0.1\n",
    "        self.b = np.zeros(output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.W) + self.b\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "        return dx, dW, db\n",
    "\n",
    "# LeNet Model\n",
    "class LeNet:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2D(input_channels=1, output_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPool2D(pool_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = Conv2D(input_channels=6, output_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = ReLU()\n",
    "        self.pool2 = MaxPool2D(pool_size=2, stride=2)\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.fc1 = FullyConnected(16 * 4 * 4, 120)  # Output size after Conv2 and Pool2 layers\n",
    "        self.relu3 = ReLU()\n",
    "\n",
    "        self.fc2 = FullyConnected(120, 84)\n",
    "        self.relu4 = ReLU()\n",
    "\n",
    "        self.fc3 = FullyConnected(84, 10)\n",
    "        self.loss_fn = SoftmaxWithLoss()\n",
    "\n",
    "        self.layers = [\n",
    "            self.conv1, self.relu1, self.pool1,\n",
    "            self.conv2, self.relu2, self.pool2,\n",
    "            self.flatten,\n",
    "            self.fc1, self.relu3,\n",
    "            self.fc2, self.relu4,\n",
    "            self.fc3\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def compute_loss(self, x, t):\n",
    "        score = self.forward(x)\n",
    "        return self.loss_fn.forward(score, t)\n",
    "\n",
    "    def backward(self):\n",
    "        dout = self.loss_fn.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "    def update(self, lr=0.01):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'W'):\n",
    "                layer.W -= lr * layer.dW\n",
    "                layer.b -= lr * layer.db\n",
    "\n",
    "# Training\n",
    "def train(model, X_train, y_train, X_test, y_test, epochs=5, batch_size=64, lr=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            loss = model.compute_loss(X_batch, y_batch)\n",
    "            model.backward()\n",
    "            model.update(lr)\n",
    "\n",
    "        # Simple accuracy check\n",
    "        y_pred = model.forward(X_test)\n",
    "        acc = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "        print(f\"Epoch {epoch+1} - Loss: {loss:.4f} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have X_train, y_train, X_test, y_test loaded and preprocessed\n",
    "# model = LeNet()\n",
    "# train(model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7d5ff",
   "metadata": {},
   "source": [
    "##### 【Problem 9 】 (Advance Challenge) Survey of famous image recognition models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c287cf",
   "metadata": {},
   "source": [
    "# **Problem 9: Survey of Famous Image Recognition Models**\n",
    "\n",
    "### 1. **AlexNet (2012)**\n",
    "\n",
    "- **Overview**: AlexNet was a groundbreaking model that won the 2012 ImageNet competition by a significant margin. It popularized deep CNNs by using multiple layers of convolution and max-pooling. It also made use of ReLU activations to speed up training.\n",
    "- **Key Features**:\n",
    "  - **Convolutional Layers**: 5 convolutional layers followed by 3 fully connected layers.\n",
    "  - **ReLU Activation**: Used to accelerate training.\n",
    "  - **Dropout**: Introduced dropout to prevent overfitting in the fully connected layers.\n",
    "  - **Data Augmentation**: Used to improve generalization by applying random transformations to the training data.\n",
    "- **Impact**: It showed that deep networks with many layers and large datasets could lead to dramatic improvements in performance.\n",
    "\n",
    "### 2. **VGG16 (2014)**\n",
    "\n",
    "- **Overview**: VGG16 is a deeper architecture that uses very small 3x3 convolution filters across all layers. It proved that stacking small filters (3x3) repeatedly leads to better performance than using larger filters.\n",
    "- **Key Features**:\n",
    "  - **Convolutional Layers**: 16 layers (13 convolutional layers and 3 fully connected layers).\n",
    "  - **Small Filters**: Used 3x3 filters for all convolutional layers.\n",
    "  - **Fully Connected Layers**: 3 fully connected layers, with the last one being a softmax output.\n",
    "  - **Max-Pooling**: After every few convolutional layers, a 2x2 max-pooling layer is used to reduce the spatial dimensions.\n",
    "- **Impact**: VGG16 demonstrated the effectiveness of deep networks and is widely used as a backbone for various tasks in computer vision.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a22d5",
   "metadata": {},
   "source": [
    "##### 【Problem 10 】 Output size and parameter count calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a715d69",
   "metadata": {},
   "source": [
    "# **Problem 10: Output Size and Parameter Count Calculation**\n",
    "\n",
    "### 1. **First Convolution Layer**:\n",
    "- **Input Size**: 144 × 144, 3 channels\n",
    "- **Filter Size**: 3 × 3, 6 channels\n",
    "- **Stride**: 1\n",
    "- **Padding**: None\n",
    "\n",
    "  **Output Size**: \n",
    "  - Height: (144 - 3 + 0) / 1 + 1 = 142\n",
    "  - Width: (144 - 3 + 0) / 1 + 1 = 142\n",
    "  - Channels: 6\n",
    "  - **Output Size** = 142 × 142 × 6\n",
    "\n",
    "  **Number of Parameters**: \n",
    "  - Each filter has 3 × 3 weights (9) per input channel. For 6 filters and 3 input channels:\n",
    "    - Weights: 3 × 3 × 3 × 6 = 162\n",
    "    - Biases: 6 (one for each filter)\n",
    "    - **Total Parameters** = 162 + 6 = 168\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Second Convolution Layer**:\n",
    "- **Input Size**: 60 × 60, 24 channels\n",
    "- **Filter Size**: 3 × 3, 48 channels\n",
    "- **Stride**: 1\n",
    "- **Padding**: None\n",
    "\n",
    "  **Output Size**: \n",
    "  - Height: (60 - 3 + 0) / 1 + 1 = 58\n",
    "  - Width: (60 - 3 + 0) / 1 + 1 = 58\n",
    "  - Channels: 48\n",
    "  - **Output Size** = 58 × 58 × 48\n",
    "\n",
    "  **Number of Parameters**: \n",
    "  - Each filter has 3 × 3 weights per input channel. For 48 filters and 24 input channels:\n",
    "    - Weights: 3 × 3 × 24 × 48 = 10368\n",
    "    - Biases: 48 (one for each filter)\n",
    "    - **Total Parameters** = 10368 + 48 = 10416\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Third Convolution Layer**:\n",
    "- **Input Size**: 20 × 20, 10 channels\n",
    "- **Filter Size**: 3 × 3, 20 channels\n",
    "- **Stride**: 2\n",
    "- **Padding**: None\n",
    "\n",
    "  **Output Size**: \n",
    "  - Height: (20 - 3 + 0) / 2 + 1 = 9\n",
    "  - Width: (20 - 3 + 0) / 2 + 1 = 9\n",
    "  - Channels: 20\n",
    "  - **Output Size** = 9 × 9 × 20\n",
    "\n",
    "  **Number of Parameters**: \n",
    "  - Each filter has 3 × 3 weights per input channel. For 20 filters and 10 input channels:\n",
    "    - Weights: 3 × 3 × 10 × 20 = 1800\n",
    "    - Biases: 20 (one for each filter)\n",
    "    - **Total Parameters** = 1800 + 20 = 1820\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebdd626",
   "metadata": {},
   "source": [
    "##### 【Problem 11 】 (Advance Challenge) Survey on filter size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842262e",
   "metadata": {},
   "source": [
    "# **Problem 11: Survey on Filter Size**\n",
    "\n",
    "### Why 3×3 filters are commonly used, rather than larger ones like 7×7?\n",
    "\n",
    "1. **Smaller Filters Capture Fine Details**: \n",
    "   - A **3x3 filter** is smaller and captures local features at a fine-grained level, making it suitable for learning smaller, more detailed features of images.\n",
    "   \n",
    "2. **Stacking 3x3 Filters to Capture Larger Receptive Fields**:\n",
    "   - By stacking multiple 3x3 filters, a network can effectively capture a larger receptive field with fewer parameters. For instance, two stacked 3x3 filters can have a receptive field of 5x5, while still maintaining a smaller number of parameters compared to a single 5x5 or 7x7 filter.\n",
    "   \n",
    "3. **Efficient Parameter Usage**: \n",
    "   - Using 3x3 filters keeps the model efficient with fewer parameters. A single 7x7 filter has more parameters and is computationally more expensive. Using 3x3 filters in depth allows for more flexible and efficient networks.\n",
    "\n",
    "4. **Empirical Success**: \n",
    "   - 3x3 filters have been empirically successful in models like VGG and ResNet. They strike a good balance between capturing local features and keeping the model relatively lightweight.\n",
    "\n",
    "### Effect of 1x1 filter without height or width?\n",
    "\n",
    "1. **Dimensionality Reduction**:\n",
    "   - A **1x1 filter** has no spatial extent (height or width) and only operates on the depth of the input. It’s used for dimensionality reduction or increasing the depth of the feature maps without altering their spatial size.\n",
    "   \n",
    "2. **Channel-wise Transformation**:\n",
    "   - It allows transforming the number of channels in the feature map, essentially working as a **pointwise** convolution. This is especially useful in architectures like **Inception** where 1x1 convolutions are used to reduce the computational burden by limiting the depth of intermediate layers.\n",
    "   \n",
    "3. **Increased Non-linearity**:\n",
    "   - The use of 1x1 convolutions increases the ability of the network to model more complex relationships by introducing more non-linearity without changing the spatial resolution.\n",
    "\n",
    "In summary, **3x3 filters** are widely used due to their computational efficiency and ability to capture detailed features, while **1x1 filters** provide an efficient way to manage depth and channel transformations in the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
